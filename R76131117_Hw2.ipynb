{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from math import sqrt\n",
    "from math import log2\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取 txt 檔案\n",
    "def load_data(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        data = [row for row in reader]\n",
    "    return data\n",
    "# 讀取資料\n",
    "data = load_data('glass.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將原始 list of list 型態的 data 轉換為 dict of list\n",
    "def table_to_column_dict(data, columns, convert_numeric = True):\n",
    "    # 初始化一個空的 dictionary，key 是 attributes 名稱，value 是空 list：\n",
    "    df_dict = {col: [] for col in columns}\n",
    "    # 對每一列資料逐欄掃描，同時把欄位名稱 (col) 跟對應值 (val) 配對起來\n",
    "    for row in data:\n",
    "        for col, val in zip(columns, row):\n",
    "            if convert_numeric:\n",
    "                try:\n",
    "                    val = float(val)\n",
    "                except ValueError:\n",
    "                    pass  # 若轉不了 float，就保持原樣（例如 Id）\n",
    "            df_dict[col].append(val)\n",
    "    return df_dict\n",
    "# 定義欄位名稱\n",
    "columns = [\"Id\",\"RI\",\"Na\",\"Mg\",\"Al\",\"Si\",\"K\",\"Ca\",\"Ba\",\"Fe\",\"class\"]\n",
    "df = table_to_column_dict(data,columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = columns.copy()\n",
    "X.remove(\"Id\")\n",
    "X.remove(\"class\")\n",
    "y = 'class'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection 函式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算 feature entropy\n",
    "def entropy(df,feature):  \n",
    "    att_value = df[feature]  # 取出 dict 的特定 attribute 的所有資料\n",
    "    value_count = Counter(att_value)          # 計算所有可能值的個數\n",
    "    total = len(att_value)\n",
    "    prob = [count / total for key,count in value_count.items()]  # 計算每個 attribute_value 的機率\n",
    "    return -sum(p * log2(p) for p in prob)\n",
    "\n",
    "# 計算特徵 X、Y 間的 Mutual Information\n",
    "def mutual_information(df,X, Y):\n",
    "    X_list = df[X]\n",
    "    Y_list = df[Y]\n",
    "    # 計算 X 和 Y 的熵\n",
    "    H_X = entropy(df ,X)\n",
    "    H_Y = entropy(df ,Y)\n",
    "    # 計算 X 和 Y 的聯合機率\n",
    "    joint_pairs = list(zip(X_list, Y_list))\n",
    "    joint_counts = Counter(joint_pairs)\n",
    "    total = len(X_list)\n",
    "    joint_prob = [count / total for key,count in joint_counts.items()]\n",
    "    H_X_Y = -sum(p * log2(p) for p in joint_prob)\n",
    "    return H_X + H_Y - H_X_Y\n",
    "    \n",
    "# 計算特徵 X、Y 的 symmetric uncertainty\n",
    "def cal_su(df,X,Y):\n",
    "    H_X = entropy(df,X)\n",
    "    H_Y = entropy(df,Y)\n",
    "    if H_X == 0 and H_Y == 0:\n",
    "        return 0\n",
    "    return 2 * (mutual_information(df,X,Y) / (H_X + H_Y))\n",
    "\n",
    "# 計算選取的特徵子集對於類別預測的 Goodness\n",
    "def Goodness(df,feature_subset,label):\n",
    "    su_X_C = 0\n",
    "    sum_su_X_Y = 0  \n",
    "    # 計算 feature_subset 內所有特徵對於類別值的 Symmetric uncertainty\n",
    "    su_X_C = sum(cal_su(df,X,label) for X in feature_subset)\n",
    "    \n",
    "    # 計算 feature_subset 內所有兩兩特徵間的 Symmetric uncertainty\n",
    "    for feature_i in feature_subset:\n",
    "        for feature_j in feature_subset:\n",
    "            sum_su_X_Y += cal_su(df,feature_i,feature_j)\n",
    "    if sum_su_X_Y == 0:\n",
    "        return 0\n",
    "    return su_X_C / sqrt(sum_su_X_Y)\n",
    "\n",
    "def forward_selection(df, X, y):\n",
    "    select_features = []    \n",
    "    best_score = 0.0        \n",
    "    remaining_features = X.copy()  \n",
    "    # 持續檢查直到沒有可以選擇的 feature\n",
    "    i = 1   \n",
    "    while(len(remaining_features) > 0):\n",
    "        scores = []  \n",
    "        for feature in remaining_features:\n",
    "            # temp_features 暫存此次循環的特徵組合 => 上回以選取好的最佳組合 select_features + 這回新選入的一個 feature\n",
    "            temp_features = select_features + [feature]\n",
    "            score = Goodness(df,temp_features,y)\n",
    "            # (目前的特徵組合, 新選進來的特徵, 此特徵組合的 Goodness)\n",
    "            scores.append((temp_features,feature,score))\n",
    "\n",
    "        # 依照 Goodness 排序\n",
    "        scores.sort(key=lambda x: x[2], reverse = True)  \n",
    "        best_new_score = float(scores[0][2])  \n",
    "        print(\"Forward Selection:\")\n",
    "        if(best_new_score > best_score):\n",
    "            best_score = best_new_score\n",
    "            select_features = scores[0][0]  # 更新成 Goodness 最優的 subset\n",
    "            if scores[0][1] in remaining_features:\n",
    "                remaining_features.remove(scores[0][1])  # 移除新選特徵\n",
    "            print(f\"Pass{i}: best_feature_subset = {select_features} , Goodness = {best_score}\")\n",
    "            i += 1\n",
    "        # 此輪中所有 feature_subset 的表現皆不如上一輪，Stop\n",
    "        else:\n",
    "            break\n",
    "    print(f\"Final select features: {select_features}, Goodness = {best_score}\")\n",
    "\n",
    "def backward_selection(df, X, y):\n",
    "    select_features = X    \n",
    "    best_score = 0.0       \n",
    "    i = 1\n",
    "    # 持續檢查到選擇的 feature 只剩下一個\n",
    "    while(len(select_features) > 1):\n",
    "        scores = [] \n",
    "        for feature in select_features:\n",
    "            temp_features = select_features.copy()\n",
    "            # 每次移除一個 feature\n",
    "            temp_features.remove(feature)\n",
    "            score = Goodness(df,temp_features,y)\n",
    "            # (目前的特徵組合, 移除的特徵, 此特徵組合的 Goodness)\n",
    "            scores.append((temp_features,feature,score))\n",
    "\n",
    "        scores.sort(key = lambda x: x[2], reverse = True)  \n",
    "        best_new_score = float(scores[0][2]) \n",
    "        print(\"Backward Selection:\")\n",
    "        if(best_new_score >= best_score):\n",
    "            best_score = best_new_score\n",
    "            select_features = scores[0][0]  # 更新成 Goodness 最優的 subset\n",
    "            if scores[0][1] in select_features:\n",
    "                select_features.remove(scores[0][1])  # 移除特徵\n",
    "            print(f\"Pass{i}: best_feature_subset = {select_features} , Goodness = {best_score}\")\n",
    "            print(f\"remove feature: {scores[0][1]}\")\n",
    "            i += 1\n",
    "        # 此輪中所有 feature_subset 的表現皆不如上一輪，Stop\n",
    "        else:\n",
    "            break\n",
    "    print(f\"Final select features: {select_features}, Goodness = {best_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equal Width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RI with equal width discretization => width = 0.0022780000000000022\n",
      "[1.513428, 1.515706, 1.517984, 1.520262, 1.52254, 1.524818, 1.527096, 1.529374, 1.531652]\n",
      "=========================================================\n",
      "Na with equal width discretization => width = 0.6649999999999998\n",
      "[11.395, 12.06, 12.725, 13.39, 14.055, 14.719999999999999, 15.384999999999998, 16.049999999999997, 16.715]\n",
      "=========================================================\n",
      "Mg with equal width discretization => width = 0.449\n",
      "[0.449, 0.898, 1.347, 1.796, 2.245, 2.694, 3.1430000000000002, 3.592, 4.041]\n",
      "=========================================================\n",
      "Al with equal width discretization => width = 0.321\n",
      "[0.611, 0.9319999999999999, 1.2530000000000001, 1.574, 1.895, 2.216, 2.537, 2.858, 3.1790000000000003]\n",
      "=========================================================\n",
      "Si with equal width discretization => width = 0.5599999999999994\n",
      "[70.37, 70.93, 71.49, 72.05, 72.61, 73.17, 73.73, 74.28999999999999, 74.85]\n",
      "=========================================================\n",
      "K with equal width discretization => width = 0.621\n",
      "[0.621, 1.242, 1.863, 2.484, 3.105, 3.726, 4.3469999999999995, 4.968, 5.589]\n",
      "=========================================================\n",
      "Ca with equal width discretization => width = 1.076\n",
      "[6.506, 7.582, 8.658, 9.734, 10.81, 11.886, 12.962, 14.038, 15.114]\n",
      "=========================================================\n",
      "Ba with equal width discretization => width = 0.315\n",
      "[0.315, 0.63, 0.9450000000000001, 1.26, 1.575, 1.8900000000000001, 2.205, 2.52, 2.835]\n",
      "=========================================================\n",
      "Fe with equal width discretization => width = 0.051000000000000004\n",
      "[0.051000000000000004, 0.10200000000000001, 0.15300000000000002, 0.20400000000000001, 0.255, 0.30600000000000005, 0.35700000000000004, 0.40800000000000003, 0.459]\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "def equal_width(df,feature,bin_num):\n",
    "    # 計算每組 bin 區間\n",
    "    att_value = df[feature]\n",
    "    max_value = float(max(att_value))\n",
    "    min_value = float(min(att_value))\n",
    "    # 計算每組區間寬度\n",
    "    width = (max_value - min_value) / bin_num\n",
    "\n",
    "    bins = []  # 儲存每組區間範圍\n",
    "    # 計算每組區間數值範圍\n",
    "    for i in range(1,bin_num):\n",
    "        cut_point = min_value + i * width\n",
    "        bins.append(cut_point) \n",
    "    print(f'{feature} with equal width discretization => width = {width}')\n",
    "    print(bins)\n",
    "    print(\"=========================================================\")\n",
    "    # 儲存 discretization 後的值\n",
    "    bin_result = []\n",
    "    for value in att_value:\n",
    "        value = float(value)\n",
    "        for i, cut_value in enumerate(bins):\n",
    "            if i == 0 and value <= cut_value:\n",
    "                bin_result.append(i + 1)\n",
    "                break\n",
    "            elif i == 0 and value > cut_value and value <= bins[i + 1]:\n",
    "                bin_result.append(i + 2)\n",
    "                break\n",
    "            elif i == bin_num - 2 and value > cut_value:\n",
    "                bin_result.append(i + 2)\n",
    "            elif value > cut_value and value <= bins[i + 1]:\n",
    "                bin_result.append(i + 2)\n",
    "                break\n",
    "    return bin_result\n",
    "\n",
    "def discretize_equal_width(df, features, bin_num):\n",
    "    new_df = []\n",
    "    bin_results = {}\n",
    "    for feature in features:\n",
    "        bin_results[feature] = equal_width(df, feature, bin_num)\n",
    "    bin_results['class'] = df['class']\n",
    "    return bin_results\n",
    "\n",
    "# 對原始資料所有連續型變數做離散化並存到新的 dict of list 裡\n",
    "equal_width_df = discretize_equal_width(df, X, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Selection:\n",
      "Pass1: best_feature_subset = ['Ba'] , Goodness = 0.3042912813744425\n",
      "Forward Selection:\n",
      "Pass2: best_feature_subset = ['Ba', 'Mg'] , Goodness = 0.39168312637244257\n",
      "Forward Selection:\n",
      "Pass3: best_feature_subset = ['Ba', 'Mg', 'Ca'] , Goodness = 0.3973212810619197\n",
      "Forward Selection:\n",
      "Pass4: best_feature_subset = ['Ba', 'Mg', 'Ca', 'Na'] , Goodness = 0.405125062147965\n",
      "Forward Selection:\n",
      "Pass5: best_feature_subset = ['Ba', 'Mg', 'Ca', 'Na', 'Al'] , Goodness = 0.4111914788502334\n",
      "Forward Selection:\n",
      "Final select features: ['Ba', 'Mg', 'Ca', 'Na', 'Al'], Goodness = 0.4111914788502334\n",
      "=================================================================================================\n",
      "Backward Selection:\n",
      "Pass1: best_feature_subset = ['Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe'] , Goodness = 0.3929712216460038\n",
      "remove feature: RI\n",
      "Backward Selection:\n",
      "Pass2: best_feature_subset = ['Na', 'Mg', 'Al', 'K', 'Ca', 'Ba', 'Fe'] , Goodness = 0.40295299406768176\n",
      "remove feature: Si\n",
      "Backward Selection:\n",
      "Pass3: best_feature_subset = ['Na', 'Mg', 'Al', 'K', 'Ca', 'Ba'] , Goodness = 0.4094585798175886\n",
      "remove feature: Fe\n",
      "Backward Selection:\n",
      "Pass4: best_feature_subset = ['Na', 'Mg', 'Al', 'Ca', 'Ba'] , Goodness = 0.4111914788502334\n",
      "remove feature: K\n",
      "Backward Selection:\n",
      "Final select features: ['Na', 'Mg', 'Al', 'Ca', 'Ba'], Goodness = 0.4111914788502334\n"
     ]
    }
   ],
   "source": [
    "# 對所有特徵離散化後的資料集做 forward selection、backward selection\n",
    "forward_selection(equal_width_df, X, 'class')\n",
    "print(\"=================================================================================================\")\n",
    "backward_selection(equal_width_df, X, 'class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equal Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"dd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RI with equal frequency discretization:\n",
      "bin1: 1.51115 <= x <= 1.51592\n",
      "bin2: 1.51592 < x <= 1.51631\n",
      "bin3: 1.51631 < x <= 1.5167\n",
      "bin4: 1.5167 < x <= 1.51735\n",
      "bin5: 1.51735 < x <= 1.51768\n",
      "bin6: 1.51768 < x <= 1.51811\n",
      "bin7: 1.51811 < x <= 1.5186\n",
      "bin8: 1.5186 < x <= 1.51994\n",
      "bin9: 1.51994 < x <= 1.52196\n",
      "bin10: 1.52196 < x <= 1.53393\n",
      "=========================================================\n",
      "Na with equal frequency discretization:\n",
      "bin1: 10.73 <= x <= 12.68\n",
      "bin2: 12.68 < x <= 12.86\n",
      "bin3: 12.86 < x <= 13.01\n",
      "bin4: 13.01 < x <= 13.21\n",
      "bin5: 13.21 < x <= 13.34\n",
      "bin6: 13.34 < x <= 13.5\n",
      "bin7: 13.5 < x <= 13.75\n",
      "bin8: 13.75 < x <= 14.15\n",
      "bin9: 14.15 < x <= 14.7\n",
      "bin10: 14.7 < x <= 17.38\n",
      "=========================================================\n",
      "Mg with equal frequency discretization:\n",
      "bin1: 0.0 <= x <= 0.33\n",
      "bin2: 0.33 < x <= 2.76\n",
      "bin3: 2.76 < x <= 3.37\n",
      "bin4: 3.37 < x <= 3.49\n",
      "bin5: 3.49 < x <= 3.55\n",
      "bin6: 3.55 < x <= 3.6\n",
      "bin7: 3.6 < x <= 3.67\n",
      "bin8: 3.67 < x <= 3.83\n",
      "bin9: 3.83 < x <= 4.49\n",
      "=========================================================\n",
      "Al with equal frequency discretization:\n",
      "bin1: 0.29 <= x <= 0.87\n",
      "bin2: 0.87 < x <= 1.15\n",
      "bin3: 1.15 < x <= 1.24\n",
      "bin4: 1.24 < x <= 1.31\n",
      "bin5: 1.31 < x <= 1.4\n",
      "bin6: 1.4 < x <= 1.52\n",
      "bin7: 1.52 < x <= 1.61\n",
      "bin8: 1.61 < x <= 1.81\n",
      "bin9: 1.81 < x <= 2.17\n",
      "bin10: 2.17 < x <= 3.5\n",
      "=========================================================\n",
      "Si with equal frequency discretization:\n",
      "bin1: 69.81 <= x <= 71.78\n",
      "bin2: 71.78 < x <= 72.14\n",
      "bin3: 72.14 < x <= 72.39\n",
      "bin4: 72.39 < x <= 72.66\n",
      "bin5: 72.66 < x <= 72.79\n",
      "bin6: 72.79 < x <= 72.92\n",
      "bin7: 72.92 < x <= 73.02\n",
      "bin8: 73.02 < x <= 73.12\n",
      "bin9: 73.12 < x <= 73.29\n",
      "bin10: 73.29 < x <= 75.41\n",
      "=========================================================\n",
      "K with equal frequency discretization:\n",
      "bin1: 0.0 <= x <= 0.02\n",
      "bin2: 0.02 < x <= 0.12\n",
      "bin3: 0.12 < x <= 0.35\n",
      "bin4: 0.35 < x <= 0.53\n",
      "bin5: 0.53 < x <= 0.57\n",
      "bin6: 0.57 < x <= 0.59\n",
      "bin7: 0.59 < x <= 0.62\n",
      "bin8: 0.62 < x <= 0.67\n",
      "bin9: 0.67 < x <= 1.46\n",
      "bin10: 1.46 < x <= 6.21\n",
      "=========================================================\n",
      "Ca with equal frequency discretization:\n",
      "bin1: 5.43 <= x <= 7.97\n",
      "bin2: 7.97 < x <= 8.12\n",
      "bin3: 8.12 < x <= 8.33\n",
      "bin4: 8.33 < x <= 8.48\n",
      "bin5: 8.48 < x <= 8.61\n",
      "bin6: 8.61 < x <= 8.79\n",
      "bin7: 8.79 < x <= 9.03\n",
      "bin8: 9.03 < x <= 9.61\n",
      "bin9: 9.61 < x <= 10.99\n",
      "bin10: 10.99 < x <= 16.19\n",
      "=========================================================\n",
      "Ba with equal frequency discretization:\n",
      "bin1: 0.0 <= x <= 0.06\n",
      "bin2: 0.06 < x <= 0.81\n",
      "bin3: 0.81 < x <= 3.15\n",
      "=========================================================\n",
      "Fe with equal frequency discretization:\n",
      "bin1: 0.0 <= x <= 0.01\n",
      "bin2: 0.01 < x <= 0.12\n",
      "bin3: 0.12 < x <= 0.2\n",
      "bin4: 0.2 < x <= 0.34\n",
      "bin5: 0.34 < x <= 0.51\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "def equal_frequency(df,feature,bin_num):\n",
    "    # 先記錄每個 instance 的原始索引及 value，len(df[feature]) 為資料總筆數\n",
    "    att_value = [(i, float(df[feature][i])) for i in range(len(df[feature]))]\n",
    "    # 以 attribute value 的值排序\n",
    "    att_value.sort(key = lambda x : x[1])\n",
    "    # 計算每個 bin 應該包含的 instances 數量\n",
    "    frequency = len(att_value) // bin_num\n",
    "    bins = [] \n",
    "    start = att_value[0][1]\n",
    "    bin_index = 1    # 記錄目前 bin \n",
    "    cur_bin_cnt = 0  # 記錄目前 bin 所分配到的 value 個數\n",
    "    # att_value 已排序過，故會由小到大遍歷，org_index 是紀錄該筆 instance 在未排序前的位置\n",
    "    for cur,(org_index,value) in enumerate(att_value):\n",
    "        # 目前 bin 的 value 數量已滿足一個 bin 所應該分配到的 frequency\n",
    "        if cur_bin_cnt >= frequency and bin_index <= bin_num:\n",
    "            # 且當前 value 不等於前一個 value 值\n",
    "            if cur < len(att_value) and value != att_value[cur - 1][1]:\n",
    "                # 若已計算到最後一個 bin\n",
    "                if bin_index == bin_num:\n",
    "                    bins.append((start,att_value[-1][1]))  # end 即為最後一筆 instance(最大值)\n",
    "                    break\n",
    "                end = value  # 該 bin 的區間最大值(不包含)\n",
    "                bins.append((start,end))\n",
    "\n",
    "                # 切換到下一個 bin\n",
    "                bin_index += 1\n",
    "                cur_bin_cnt = 0\n",
    "                start = att_value[cur][1]  # att_value[i][1] 為下個 bin 的起點\n",
    "        # 該 bin 裡的 instances 個數加一\n",
    "        cur_bin_cnt += 1\n",
    "\n",
    "    # 上述設定在切換下個 bin 時才將 (start,end) 進 bins\n",
    "    # 有可能迴圈結束，最後一個 bin 的值個數不足一個 frequency，不會切換 bin，因此需要額外判斷防止最後一個 bin 消失\n",
    "    if len(bins) < bin_num:\n",
    "        end = att_value[-1][1]   # end 為最後一個元素(最大值)\n",
    "        bins.append((start, end))\n",
    "\n",
    "    print(f'{feature} with equal frequency discretization:')\n",
    "    for i, (start, end) in enumerate(bins):\n",
    "        if i == 0:\n",
    "            print(f'bin{i + 1}: {start} <= x <= {end}')\n",
    "        else:\n",
    "            print(f'bin{i + 1}: {start} < x <= {end}')\n",
    "    print(\"=========================================================\")\n",
    "    # 對 df 做離散化並將新值存到一個 dict of list\n",
    "    org_value = df[feature]\n",
    "    bin_result = []\n",
    "    for value in org_value:\n",
    "        value = float(value)\n",
    "        for i, (start, end) in enumerate(bins):\n",
    "            if i == 0 and value >= start and value <= end:\n",
    "                bin_result.append(i + 1)\n",
    "                break\n",
    "            elif value > start and value <= end:\n",
    "                bin_result.append(i + 1)\n",
    "                break\n",
    "    return bin_result\n",
    "\n",
    "\n",
    "def discretize_equal_frequency(df, features, bin_num):\n",
    "    new_df = []\n",
    "    # 對每個 feature 做離散化，回傳 bin 結果(dict of list）\n",
    "    bin_results = {}\n",
    "    for feature in features:\n",
    "        bin_results[feature] = equal_frequency(df, feature, bin_num)\n",
    "    bin_results['class'] = df['class']\n",
    "    return bin_results\n",
    "\n",
    "equal_frequency_df = discretize_equal_frequency(df,X,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RI with equal frequency discretization:\n",
      "[1.51592, 1.51631, 1.5167, 1.51735, 1.51768, 1.51811, 1.5186, 1.51994, 1.52196]\n",
      "=========================================================\n",
      "Na with equal frequency discretization:\n",
      "[12.68, 12.86, 13.01, 13.21, 13.34, 13.5, 13.75, 14.15, 14.7]\n",
      "=========================================================\n",
      "Mg with equal frequency discretization:\n",
      "[0.33, 2.76, 3.37, 3.49, 3.55, 3.6, 3.67, 3.83]\n",
      "=========================================================\n",
      "Al with equal frequency discretization:\n",
      "[0.87, 1.15, 1.24, 1.31, 1.4, 1.52, 1.61, 1.81, 2.17]\n",
      "=========================================================\n",
      "Si with equal frequency discretization:\n",
      "[71.78, 72.14, 72.39, 72.66, 72.79, 72.92, 73.02, 73.12, 73.29]\n",
      "=========================================================\n",
      "K with equal frequency discretization:\n",
      "[0.02, 0.12, 0.35, 0.53, 0.57, 0.59, 0.62, 0.67, 1.46]\n",
      "=========================================================\n",
      "Ca with equal frequency discretization:\n",
      "[7.97, 8.12, 8.33, 8.48, 8.61, 8.79, 9.03, 9.61, 10.99]\n",
      "=========================================================\n",
      "Ba with equal frequency discretization:\n",
      "[0.06, 0.81]\n",
      "=========================================================\n",
      "Fe with equal frequency discretization:\n",
      "[0.01, 0.12, 0.2, 0.34]\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "def equal_frequency(df,feature,bin_num):\n",
    "    # 先記錄每個 instance 的原始索引及 value，len(df[feature]) 為資料總筆數\n",
    "    att_value = [(i, float(df[feature][i])) for i in range(len(df[feature]))]\n",
    "    # 以 attribute value 的值排序\n",
    "    att_value.sort(key = lambda x : x[1])\n",
    "    # 計算每個 bin 應該包含的 instances 數量\n",
    "    frequency = len(att_value) // bin_num\n",
    "    bins = [] \n",
    "    start = att_value[0][1]\n",
    "    bin_index = 1    # 記錄目前 bin \n",
    "    cur_bin_cnt = 0  # 記錄目前 bin 所分配到的 value 個數\n",
    "    # att_value 已排序過，故會由小到大遍歷，org_index 是紀錄該筆 instance 在未排序前的位置\n",
    "    for cur,(org_index,value) in enumerate(att_value):\n",
    "        # 目前 bin 的 value 數量已滿足一個 bin 所應該分配到的 frequency\n",
    "        if cur_bin_cnt >= frequency and bin_index <= bin_num:\n",
    "            # 且當前 value 不等於前一個 value 值\n",
    "            if cur < len(att_value) and value != att_value[cur - 1][1]:\n",
    "                # 若已計算到最後一個 bin\n",
    "                if bin_index == bin_num:\n",
    "                    bins.append((start,att_value[-1][1]))  # end 即為最後一筆 instance(最大值)\n",
    "                    break\n",
    "                end = value  # 該 bin 的區間最大值(不包含)\n",
    "                bins.append((start,end))\n",
    "\n",
    "                # 切換到下一個 bin\n",
    "                bin_index += 1\n",
    "                cur_bin_cnt = 0\n",
    "                start = att_value[cur][1]  # att_value[i][1] 為下個 bin 的起點\n",
    "        # 該 bin 裡的 instances 個數加一\n",
    "        cur_bin_cnt += 1\n",
    "\n",
    "    # 上述設定在切換下個 bin 時才將 (start,end) 進 bins\n",
    "    # 有可能迴圈結束，最後一個 bin 的值個數不足一個 frequency，不會切換 bin，因此需要額外判斷防止最後一個 bin 消失\n",
    "    if len(bins) < bin_num:\n",
    "        end = att_value[-1][1]   # end 為最後一個元素(最大值)\n",
    "        bins.append((start, end))\n",
    "    print(f'{feature} with equal frequency discretization:')\n",
    "    print_bins = []\n",
    "    for i, (start, end) in enumerate(bins):\n",
    "        if i == len(bins) - 1:\n",
    "            break\n",
    "        print_bins.append(end)\n",
    "    print(print_bins)\n",
    "    print(\"=========================================================\")\n",
    "    # 對 df 做離散化並將新值存到一個 dict of list\n",
    "    org_value = df[feature]\n",
    "    bin_result = []\n",
    "    for value in org_value:\n",
    "        value = float(value)\n",
    "        for i, (start, end) in enumerate(bins):\n",
    "            if i == 0 and value >= start and value <= end:\n",
    "                bin_result.append(i + 1)\n",
    "                break\n",
    "            elif value > start and value <= end:\n",
    "                bin_result.append(i + 1)\n",
    "                break\n",
    "    return bin_result\n",
    "\n",
    "\n",
    "def discretize_equal_frequency(df, features, bin_num):\n",
    "    new_df = []\n",
    "    # 對每個 feature 做離散化，回傳 bin 結果(dict of list）\n",
    "    bin_results = {}\n",
    "    for feature in features:\n",
    "        bin_results[feature] = equal_frequency(df, feature, bin_num)\n",
    "    bin_results['class'] = df['class']\n",
    "    return bin_results\n",
    "\n",
    "equal_frequency_df = discretize_equal_frequency(df,X,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Selection:\n",
      "Pass1: best_feature_subset = ['Mg'] , Goodness = 0.24095902540972278\n",
      "Forward Selection:\n",
      "Pass2: best_feature_subset = ['Mg', 'Ba'] , Goodness = 0.31902345088124423\n",
      "Forward Selection:\n",
      "Pass3: best_feature_subset = ['Mg', 'Ba', 'Al'] , Goodness = 0.35549303947336497\n",
      "Forward Selection:\n",
      "Pass4: best_feature_subset = ['Mg', 'Ba', 'Al', 'RI'] , Goodness = 0.3752863615702465\n",
      "Forward Selection:\n",
      "Pass5: best_feature_subset = ['Mg', 'Ba', 'Al', 'RI', 'K'] , Goodness = 0.3877323986697869\n",
      "Forward Selection:\n",
      "Pass6: best_feature_subset = ['Mg', 'Ba', 'Al', 'RI', 'K', 'Na'] , Goodness = 0.3907283561012959\n",
      "Forward Selection:\n",
      "Final select features: ['Mg', 'Ba', 'Al', 'RI', 'K', 'Na'], Goodness = 0.3907283561012959\n",
      "=================================================================================================\n",
      "Backward Selection:\n",
      "Pass1: best_feature_subset = ['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba'] , Goodness = 0.3827512165073733\n",
      "remove feature: Fe\n",
      "Backward Selection:\n",
      "Pass2: best_feature_subset = ['RI', 'Na', 'Mg', 'Al', 'K', 'Ca', 'Ba'] , Goodness = 0.38704071339993934\n",
      "remove feature: Si\n",
      "Backward Selection:\n",
      "Pass3: best_feature_subset = ['RI', 'Na', 'Mg', 'Al', 'K', 'Ba'] , Goodness = 0.39072835610129586\n",
      "remove feature: Ca\n",
      "Backward Selection:\n",
      "Final select features: ['RI', 'Na', 'Mg', 'Al', 'K', 'Ba'], Goodness = 0.39072835610129586\n"
     ]
    }
   ],
   "source": [
    "# 對所有特徵離散化後的資料集做 forward selection、backward selection\n",
    "forward_selection(equal_frequency_df, X, 'class')\n",
    "print(\"=================================================================================================\")\n",
    "backward_selection(equal_frequency_df, X, 'class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entropy Based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 計算區間內類別值的 entropy\n",
    "def Ent(df,class_label):\n",
    "    class_value = df[class_label]\n",
    "    cnt = Counter(class_value)\n",
    "    prob = [count / len(class_value) for i,count in cnt.items()]\n",
    "    Ent = -sum(p * log2(p) for p in prob) \n",
    "    return Ent\n",
    "\n",
    "# cut_index 為資料被分割成兩個 subset 時，「右側區間的起始 index」，此函式計算切割後的資訊增益\n",
    "def info_gain(df,cut_index,feature,class_label):\n",
    "    # 將原始資料 feature 和 class 的對應資料與索引組合起來，(索引 , feature 值 , 類別值)\n",
    "    new_df = [(i,float(df[feature][i]), df[class_label][i]) for i in range(len(df[feature]))]\n",
    "    feature_class = sorted(new_df,key = lambda x : x[1])  # x[1] 即為 feature 值\n",
    "    # 取得排序後 feature 值的原始 index \n",
    "    sorted_index = [row[0] for row in feature_class]\n",
    "    left_index = sorted_index[:cut_index]\n",
    "    right_index = sorted_index[cut_index:]\n",
    "    total = len(df[class_label])\n",
    "    # 切左右兩側，從上述得到的左右區間包含的 instances 的原始索引來分配\n",
    "    left = {class_label : [df[class_label][i] for i in left_index]}\n",
    "    right = {class_label : [df[class_label][i] for i in right_index]}\n",
    "    Ent_cut = len(left[class_label]) / total * Ent(left,class_label) + len(right[class_label]) / total * Ent(right,class_label)\n",
    "\n",
    "    info_gain = Ent(df,class_label) - Ent_cut\n",
    "    return info_gain\n",
    "\n",
    "# 找 feature 的最佳切點\n",
    "def find_cut_point(df, feature, class_label):\n",
    "    best_info_gain = -1\n",
    "    best_cut_value = None  # 最佳切點的 instance 值\n",
    "    # 將 feature 和 class 的對應資料與索引組合起來，(索引 , feature 值 , 類別值)\n",
    "    feature_with_class = [(i, float(df[feature][i]),df[class_label][i]) for i in range(len(df[class_label]))]\n",
    "    sorted_data = sorted(feature_with_class,key = lambda x : x[1])  # x[1] 為 feature 值\n",
    "    for i in range(1,len(sorted_data)):\n",
    "        # 相鄰兩樣本類別值不一樣，其平均值可以當切點，且 i 開始為右區間\n",
    "        if sorted_data[i][2] != sorted_data[i - 1][2]:\n",
    "            cur_info_gain = info_gain(df,i,feature,class_label)\n",
    "            if cur_info_gain > best_info_gain:\n",
    "                best_info_gain = cur_info_gain\n",
    "                best_cut_value = (sorted_data[i][1] + sorted_data[i - 1][1]) / 2\n",
    "    return best_info_gain , best_cut_value\n",
    "\n",
    "# 對整個 df 的 feature 欄位做 entropy_base 切割，找所有切點，返回切割點 list\n",
    "def split(df,feature,class_label,cut_points):\n",
    "    # 若傳進來的 cut_points 為空，代表區間無可用的切割點\n",
    "    if cut_points is None:\n",
    "        cut_points = []\n",
    "    best_info_gain,best_cut_value = find_cut_point(df,feature,class_label)\n",
    "\n",
    "    # 若區間的 class 值或 feature 值都是一樣的，或只剩一個 instance，代表切割無意義\n",
    "    if (len(df[class_label]) <= 1 or best_cut_value is None or\n",
    "        len(set(df[class_label])) == 1 or len(set(df[feature])) == 1):\n",
    "        return []\n",
    "    \n",
    "    # 創造兩個 dict of list 儲存切割後的 feature 與 class 欄位\n",
    "    left_set = {feature : [],class_label : []}\n",
    "    right_set = {feature : [],class_label : []}\n",
    "    for i in range(len(df[feature])):\n",
    "        # 分配 instances 至對應的區間\n",
    "        value = float(df[feature][i])\n",
    "        if value <= best_cut_value:\n",
    "            left_set[feature].append(value)\n",
    "            left_set[class_label].append(df[class_label][i])\n",
    "        else:\n",
    "            right_set[feature].append(value)\n",
    "            right_set[class_label].append(df[class_label][i])\n",
    "    # 切割完，若任一區間沒有資料，或分割後區間內容與分割前一樣，代表分割沒有幫助 \n",
    "    if (len(left_set[feature]) == 0 or len(right_set[feature]) == 0 or\n",
    "        len(left_set[feature]) == len(df[feature]) or len(right_set[feature]) == len(df[feature])):\n",
    "        return []\n",
    "    # 計算 MDLPC criterion 的 threshold\n",
    "\n",
    "    # 計算初始區間、切割後的左右區間個包含的 class 種類數量\n",
    "    k = len(set(df[class_label]))\n",
    "    k1 = len(set(left_set[class_label]))\n",
    "    k2 = len(set(right_set[class_label]))\n",
    "    N = len(df[feature])\n",
    "    delta = log2(3 ** k - 2) - ((k * Ent(df,class_label) \n",
    "        - k1 * Ent(left_set,class_label)\n",
    "        - k2 * Ent(right_set,class_label)))\n",
    "    threshold = log2(N - 1) / N + delta / N\n",
    "\n",
    "    # 最好的切割點的 gain 未超過 threshold，停止\n",
    "    if best_info_gain <= threshold :\n",
    "        return []\n",
    "    \n",
    "    cut_points.append(best_cut_value)\n",
    "    # 對左右區間遞迴做 entropy_base 切割\n",
    "    split(left_set,feature,class_label,cut_points)\n",
    "    split(right_set,feature,class_label,cut_points)\n",
    "    return cut_points\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RI with entropy base discretization:\n",
      "[1.517335, 1.517985]\n",
      "=========================================================\n",
      "Na with entropy base discretization:\n",
      "[14.065]\n",
      "=========================================================\n",
      "Mg with entropy base discretization:\n",
      "[0.0, 2.6950000000000003]\n",
      "=========================================================\n",
      "Al with entropy base discretization:\n",
      "[1.4, 1.76]\n",
      "=========================================================\n",
      "Si with entropy base discretization:\n",
      "[]\n",
      "=========================================================\n",
      "K with entropy base discretization:\n",
      "[0.0, 0.035, 0.055, 0.62, 0.745]\n",
      "=========================================================\n",
      "Ca with entropy base discretization:\n",
      "[7.02, 8.32, 10.17]\n",
      "=========================================================\n",
      "Ba with entropy base discretization:\n",
      "[0.0, 0.335]\n",
      "=========================================================\n",
      "Fe with entropy base discretization:\n",
      "[0.0]\n",
      "=========================================================\n"
     ]
    }
   ],
   "source": [
    "# 照上述的切點做 discretization\n",
    "def discretize_entropy_base(df,features,class_label):\n",
    "    bin_results = {}\n",
    "    for feature in features:\n",
    "        print(f'{feature} with entropy base discretization:')    \n",
    "        cut_points = []\n",
    "        cut_points = split(df,feature,\"class\",cut_points)\n",
    "        # 若沒有切點，代表整個特徵內容會被離散為同個類別\n",
    "        if cut_points == []:\n",
    "            ent_base_res = [1] * len(df[feature])\n",
    "            bin_results[feature] = ent_base_res\n",
    "        else:\n",
    "            cut_points = sorted(cut_points)\n",
    "            org_value = df[feature]     # 紀錄特徵值的原始值\n",
    "            ent_base_res = []           # 紀錄離散化後的特徵值\n",
    "            # 對每個 feature 值做離散化分配\n",
    "            for value in org_value:\n",
    "                value = float(value)\n",
    "                for i,cut_point in enumerate(cut_points):\n",
    "                    # 只有一個切割點，只會被切成兩個區間\n",
    "                    if len(cut_points) == 1:\n",
    "                        if value <= cut_point:\n",
    "                            ent_base_res.append(i + 1)\n",
    "                        else:\n",
    "                            ent_base_res.append(i + 2)\n",
    "                    # 有兩個以上的切點\n",
    "                    else:\n",
    "                        if i == 0 and value <= cut_point:\n",
    "                            ent_base_res.append(i + 1)\n",
    "                        elif i == len(cut_points) - 1 and value > cut_point:\n",
    "                            ent_base_res.append(i + 1)\n",
    "                        elif value > cut_point and value <= cut_points[i - 1]:\n",
    "                            ent_base_res.append(i + 1)\n",
    "            bin_results[feature] = ent_base_res\n",
    "        print(f\"{cut_points}\")\n",
    "        print(\"=========================================================\")\n",
    "    bin_results['class'] = df['class']\n",
    "    return bin_results\n",
    "entropy_base_df = discretize_entropy_base(df,X,'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Selection:\n",
      "Pass1: best_feature_subset = ['Mg'] , Goodness = 0.37040112253047947\n",
      "Forward Selection:\n",
      "Pass2: best_feature_subset = ['Mg', 'Ba'] , Goodness = 0.4209779203953104\n",
      "Forward Selection:\n",
      "Final select features: ['Mg', 'Ba'], Goodness = 0.4209779203953104\n",
      "=================================================================================================\n",
      "Backward Selection:\n",
      "Pass1: best_feature_subset = ['Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe'] , Goodness = 0.40630426699936245\n",
      "remove feature: RI\n",
      "Backward Selection:\n",
      "Pass2: best_feature_subset = ['Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba'] , Goodness = 0.4168011479585509\n",
      "remove feature: Fe\n",
      "Backward Selection:\n",
      "Pass3: best_feature_subset = ['Na', 'Mg', 'Al', 'Si', 'Ca', 'Ba'] , Goodness = 0.4258437899890787\n",
      "remove feature: K\n",
      "Backward Selection:\n",
      "Pass4: best_feature_subset = ['Na', 'Mg', 'Al', 'Ca', 'Ba'] , Goodness = 0.4258437899890787\n",
      "remove feature: Si\n",
      "Backward Selection:\n",
      "Final select features: ['Na', 'Mg', 'Al', 'Ca', 'Ba'], Goodness = 0.4258437899890787\n"
     ]
    }
   ],
   "source": [
    "# 對所有特徵離散化後的資料集做 forward selection、backward selection\n",
    "forward_selection(entropy_base_df, X, 'class')\n",
    "print(\"=================================================================================================\")\n",
    "backward_selection(entropy_base_df, X, 'class')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
